{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9567dd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa8d482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8979027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103808ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866c5e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MNIST(root='data', train=True, transform=transform, download=True)\n",
    "test_data = MNIST(root='data', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da18f9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.data[0]\n",
    "# test_data.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f8271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff279b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(64, 10),\n",
    "            # nn.ReLU()   \n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd198025",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DigitClassifier().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f5b9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.view(images.size(0), -1).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        total_loss += loss.item() \n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}], Step [{labels.size(0)}], Loss: {loss.item():.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1068d923",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50e5baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(images.size(0), -1).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        predictions = outputs.argmax(dim=1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predictions == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the model on the test images: {100 * correct / total} %')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cea3592",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'digit_classifier.pth')\n",
    "print('Model saved to digit_classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3b193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "image, true_label = test_data[index]\n",
    "\n",
    "plt.imshow(image.squeeze(), cmap='gray')\n",
    "plt.title(f'True Label: {true_label}')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "image_flat = image.view(1, -1).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(image_flat)\n",
    "    predicted_label = output.argmax(dim=1).item()\n",
    "\n",
    "print(f'Index: {index}')\n",
    "print(f'True Label: {true_label}')\n",
    "print(f'Predicted Label: {predicted_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3cb0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for _ in range(5):\n",
    "    index = random.randint(0, len(test_data)-1)\n",
    "    image, true_label = test_data[index]\n",
    "\n",
    "    plt.imshow(image.squeeze(), cmap='gray')\n",
    "    plt.title(f'True Label: {true_label}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    image_flat = image.view(1, -1).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image_flat)\n",
    "        predicted_label = output.argmax(dim=1).item()\n",
    "\n",
    "    print(f'Index: {index}')\n",
    "    print(f'True Label: {true_label}')\n",
    "    print(f'Predicted Label: {predicted_label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d66b6aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Predictions: 4894 out of 5000\n",
      "Incorrect Predictions: 106 out of 5000\n",
      "Accuracy over 5000 random samples: 97.88 %\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "n = 5000\n",
    "cnt = 0\n",
    "for _ in range(n):\n",
    "    index = random.randint(0, len(test_data)-1)\n",
    "    image, true_label = test_data[index]\n",
    "\n",
    "    # plt.imshow(image.squeeze(), cmap='gray')\n",
    "    # plt.title(f'True Label: {true_label}')\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "    image_flat = image.view(1, -1).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image_flat)\n",
    "        predicted_label = output.argmax(dim=1).item()\n",
    "\n",
    "    if true_label == predicted_label:\n",
    "        cnt += 1\n",
    "\n",
    "    # print('---')\n",
    "    # print(f'Index: {index}')\n",
    "    # print(f'True Label: {true_label}')\n",
    "    # print(f'Predicted Label: {predicted_label}')\n",
    "print(f'Correct Predictions: {cnt} out of {n}')\n",
    "print(f'Incorrect Predictions: {n - cnt} out of {n}')\n",
    "print(f'Accuracy over {n} random samples: {100 * cnt / n} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
